{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE Winter School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning for Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:**\n",
    "[Anthony Strittmatter](http://www.anthonystrittmatter.com)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the hedonic prices of used-cars. For this purpose, we web-scrape data from the online auction platform *MyLemons*. We restrict the sample to BMW 320 series, Opel Astra, Mercedes C-class, VW Golf, and VW Passat. We select used-cars with a mileage between 10,000-200,000 km and an age between 1-20 years. The data is stored in the file *used_cars.csv*.  \n",
    "\n",
    "We observe the following variables:\n",
    "\n",
    "\n",
    "|Variable name| Description|\n",
    "|:----|:----|\n",
    "|**Outcome variable** ||\n",
    "|*first_price*| First asking price in 1,000 CHF |\n",
    "|**Covariates**| |\n",
    "|*bmw_320, opel_astra, mercedes_c, vw_golf, vw_passat*| Dummies for the car make and model|\n",
    "|*mileage*| Mileage of the used car (in 1,000 km)|\n",
    "|*age_car_years*| Age of the used car (in years)|\n",
    "|*mileage2, mileage3, mileage4, age_car_years2, age_car_years3, age_car_years4*| Squared, cubic, and quadratic *mileage* and *age_car_years* |\n",
    "|*diesel*| Dummy for diesel engines |\n",
    "|*private_seller*| Dummy for private seller (as opposed to professional used car sellers) |\n",
    "|*other_car_owner*| Number of previous caar owners |\n",
    "|*guarantee*| Dummy indicating that the seller offers a guarantee for the used car|\n",
    "|*maintenance_cert*| Dummy indicating that the seller has a complete maintenace certificate for the used car|\n",
    "|*pm_green*| Dummy indicating that the used car has low particular matter emissions|\n",
    "|*co2_em*| CO2 emssion (in g/km)|\n",
    "|*page_title* | Text in the title of the used car offer |\n",
    "|*dur_next_ins_0*| Dummy indicating that the duration until the next general inspection is less than a years |\n",
    "|*dur_next_ins_1_2*| Dummy indicating that the duration until the next general inspection is between 1 and 2 years |\n",
    "|*new_inspection*| Dummy indicating that the used car has a new general inspection |\n",
    "|*euro_1, euro_2, euro_3, euro_4, euro_5, euro_6*| Dummies for EURO emission norms |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  Load Packages  ########################\n",
    "\n",
    "# List of required packages\n",
    "pkgs <- c('tidyverse','glmnet','corrplot','plotmo')\n",
    "\n",
    "# Load packages\n",
    "for(pkg in pkgs){\n",
    "    install.packages(pkg)\n",
    "    library(pkg, character.only = TRUE)\n",
    "}\n",
    "\n",
    "print('All packages successfully installed and loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data frame and label the covariates. We select a subsample of 300 used-cars in order to decrease the computation time while you are testing your code. We can use the entire sample of 104,719 used cars after we are finised with programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  Load Data Frame  ########################\n",
    "\n",
    "# Load data frame\n",
    "data_raw <- read.csv(\"Data/mylemon.csv\",header=TRUE, sep=\",\")\n",
    "\n",
    "# Selection of Subsample size, max. 104,721 observations\n",
    "# Select smaller subsample to decrease computation time\n",
    "set.seed(1001) # set starting value for random number generator\n",
    "n_obs <- 300\n",
    "df <- data_raw %>%\n",
    "  dplyr::sample_n(n_obs)\n",
    "\n",
    "print('Data successfully loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Training and Test Sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare the relative prediction power of different estimation procedures based on the out-of-sample MSE and $R^2$. For this purpose, we create an hold-out-sample. Additionally, we generate 100 random variables which are unrelated to the used-car prices. These variables create additional noise in the estimation. Ideally, the Lasso approach should not select those variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  Take Hold-Out-Sample  ########################\n",
    "set.seed(100219) # set starting value for random number generator\n",
    "\n",
    "# Partition the sample\n",
    "df_part <- modelr::resample_partition(df, c(obs = 0.8, hold_out = 0.2))\n",
    "df_train <- as.data.frame(df_part$obs) # Training data\n",
    "df_test <- as.data.frame(df_part$hold_out) # Test data\n",
    "\n",
    "# Outcomes\n",
    "price_train <- as.matrix(df_train[,2])\n",
    "price_test <- as.matrix(df_test[,2])\n",
    "\n",
    "# Covariates/Features\n",
    "covariates_train <- as.matrix(df_train[,c(3:ncol(df_train))])\n",
    "covariates_test <- as.matrix(df_test[,c(3:ncol(df_test))])\n",
    "\n",
    "print('The data is now ready for your first analysis!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  Correlation Matrix  ########################\n",
    "\n",
    "corr = cor(covriates)\n",
    "corrplot(corr, type = \"upper\", tl.col = \"black\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the used-car prices using an OLS model which includes all (relevant and irrelavant) covariates.\n",
    "\n",
    "**Replace parameters in questionsmarks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  OLS Model  ######################## \n",
    "\n",
    "# Setup the formula of the linear regression model\n",
    "#sumx <- paste(covariates, collapse = \" + \")  \n",
    "#linear <- paste(\"first_price_obs\",paste(sumx, sep=\" + \"), sep=\" ~ \")\n",
    "#linear <- as.formula(linear)\n",
    "\n",
    "# Setup the data for linear regression\n",
    "#data <- as.data.frame(covariates_obs)\n",
    "\n",
    "# Estimate OLS model\n",
    "ols <- lm(first_price_obs ~., as.data.frame(covariates_obs))\n",
    "summary(ols)\n",
    "# Some variables might be dropped because of perfect colinearity (121 covariates - 240 observations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrapolate fitted values to the hold-out-sample.\n",
    "\n",
    "**Replace parameters in questionsmarks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample fitted values\n",
    "fit1_in <- predict.lm(ols)\n",
    "\n",
    "# Out-of-sample fitted values\n",
    "fit1_out <- predict.lm(ols, newdata = data.frame(covariates_hold_out))\n",
    "\n",
    "# In-sample performance measures\n",
    "#mse1_in <- round(mean((first_price_obs - fit1_in)^2),digits=3)\n",
    "rsquared_in <- round(1-mean((first_price_obs - fit1_in)^2)/mean((first_price_obs - mean(first_price_obs))^2),digits=3)\n",
    "#print(paste0(\"In-Sample MSE OLS: \", mse1_in))\n",
    "print(paste0(\"In-Sample R-squared OLS: \", rsquared_in))\n",
    "\n",
    "# Out-of-sample performance measures\n",
    "#mse1_out <- round(mean((first_price_hold_out - fit1_out)^2),digits=3)\n",
    "rsquared_out <- round(1-mean((first_price_hold_out - fit1_out)^2)/mean((first_price_hold_out - mean(first_price_hold_out))^2),digits=3)\n",
    "#print(paste0(\"Out-of-Sample MSE OLS: \", mse1_out))\n",
    "print(paste0(\"Out-of-Sample R-squared OLS: \", rsquared_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the in- and out-of-sample performance using MSE and $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LASSO minimises the objective function\n",
    "\\begin{equation*}\n",
    "\\min_{\\beta} \\left\\{ \\sum_{i=1}^{N} \\left( Y_i-  \\beta_0 -\\sum_{j=1}^{p}X_{ij}\\beta_j \\right)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j| \\right\\}.\n",
    "\\end{equation*}\n",
    "First we have to find the optimal tuning parameter $\\lambda$ via cross-validation (CV).\n",
    "\n",
    "**Replace parameters in questionsmarks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  CV-LASSO  ######################## \n",
    "p = 1 # 1 for LASSO, 0 for Ridge\n",
    "\n",
    "set.seed(10101)\n",
    "lasso.linear <- cv.glmnet(covariates_obs, first_price_obs, alpha=p, \n",
    "                          nlambda = 100, type.measure = 'mse')\n",
    "# nlambda specifies the number of different lambda values on the grid (log-scale)\n",
    "# type.measure spciefies that the optimality criteria is the MSE in CV-samples\n",
    "\n",
    "# Plot MSE in CV-Samples for different values of lambda\n",
    "plot(lasso.linear)\n",
    "\n",
    "# Optimal Lambda\n",
    "print(paste0(\"Lambda minimising CV-MSE: \", round(lasso.linear$lambda.min,digits=8)))\n",
    "# 1 standard error rule reduces the number of included covariates\n",
    "print(paste0(\"Lambda 1 standard error rule: \", round(lasso.linear$lambda.1se,digits=8)))\n",
    "\n",
    "# Number of Non-Zero Coefficients\n",
    "print(paste0(\"Number of selected covariates (lambd.min): \",lasso.linear$glmnet.fit$df[lasso.linear$glmnet.fit$lambda==lasso.linear$lambda.min]))\n",
    "print(paste0(\"Number of selected covariates (lambd.1se): \",lasso.linear$glmnet.fit$df[lasso.linear$glmnet.fit$lambda==lasso.linear$lambda.1se]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Lasso Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  Visualisation of LASSO  ######################## \n",
    "\n",
    "glmcoef<-coef(lasso.linear,lasso.linear$lambda.1se)\n",
    "coef.increase<-dimnames(glmcoef[glmcoef[,1]>0,0])[[1]]\n",
    "coef.decrease<-dimnames(glmcoef[glmcoef[,1]<0,0])[[1]]\n",
    "\n",
    "lambda_min =  lasso.linear$glmnet.fit$lambda[26]/lasso.linear$glmnet.fit$lambda[1]\n",
    "set.seed(10101)\n",
    "mod <- glmnet(covariates_obs, first_price_obs, lambda.min.ratio = lambda_min, alpha=p)\n",
    "maxcoef<-coef(mod,s=lambda_min)\n",
    "coef<-dimnames(maxcoef[maxcoef[,1]!=0,0])[[1]]\n",
    "allnames<-dimnames(maxcoef[maxcoef[,1]!=0,0])[[1]][order(maxcoef[maxcoef[,1]!=0,ncol(maxcoef)],decreasing=TRUE)]\n",
    "allnames<-setdiff(allnames,allnames[grep(\"Intercept\",allnames)])\n",
    "\n",
    "#assign colors\n",
    "cols<-rep(\"gray\",length(allnames))\n",
    "cols[allnames %in% coef.increase]<-\"red\"   \n",
    "cols[allnames %in% coef.decrease]<- \"green\"\n",
    "\n",
    "plot_glmnet(mod,label=TRUE,s=lasso.linear$lambda.1se,col= cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Lasso Coefficients\n",
    "\n",
    "**Replace parameters in questionsmarks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  Plot LASSO Coefficients  ########################\n",
    "\n",
    "print('LASSO coefficients')\n",
    "\n",
    "glmcoef<-coef(lasso.linear, lasso.linear$lambda.1se)\n",
    "print(glmcoef)\n",
    "# the LASSO coefficients are biased because of the penalty term\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Sample Perforamce Measures\n",
    "\n",
    "**Replace parameters in questionsmarks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## In-Sample Performance of LASSO  ######################## \n",
    "\n",
    "# Estimate LASSO model \n",
    "# Use Lambda that minizes CV-MSE\n",
    "set.seed(10101)\n",
    "lasso.fit.min <- glmnet(covariates_obs, first_price_obs, lambda = lasso.linear$lambda.min)\n",
    "yhat.lasso.min <- predict(lasso.fit.min, covariates_obs)\n",
    "\n",
    "# Use 1 standard error rule\n",
    "set.seed(10101)\n",
    "lasso.fit.1se <- glmnet(covariates_obs, first_price_obs, lambda = lasso.linear$lambda.1se)\n",
    "yhat.lasso.1se <- predict(lasso.fit.1se, covariates_obs)\n",
    "\n",
    "# In-sample performance measures\n",
    "print(paste0(\"In-Sample MSE OLS: \", mse1_in))\n",
    "print(paste0(\"In-Sample R-squared OLS: \", rsquared_in))\n",
    "\n",
    "mse2_in <- round(mean((first_price_obs - yhat.lasso.min)^2),digits=3)\n",
    "rsquared2_in <- round(1-mean((first_price_obs - yhat.lasso.min)^2)/mean((first_price_obs - mean(first_price_obs))^2),digits=3)\n",
    "print(paste0(\"In-Sample MSE Lasso (lambda.min): \", mse2_in))\n",
    "print(paste0(\"In-Sample R-squared Lasso (lambda.min): \", rsquared2_in))\n",
    "\n",
    "mse3_in <- round(mean((first_price_obs - yhat.lasso.1se)^2),digits=3)\n",
    "rsquared3_in <- round(1-mean((first_price_obs - yhat.lasso.1se)^2)/mean((first_price_obs - mean(first_price_obs))^2),digits=3)\n",
    "print(paste0(\"In-Sample MSE Lasso(lambda.1se): \", mse3_in))\n",
    "print(paste0(\"In-Sample R-squared Lasso (lambda.1se): \", rsquared3_in))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Perforamce Measures\n",
    "\n",
    "**Replace parameters in questionsmarks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Out-of-Sample Performance of LASSO  ######################## \n",
    "\n",
    "# Extrapolate Lasso fitted values to hold-out-sample\n",
    "yhat.lasso.min <- predict(lasso.fit.min, covariates_hold_out)\n",
    "yhat.lasso.1se <- predict(lasso.fit.1se, covariates_hold_out)\n",
    "\n",
    "# Out-of-sample performance measures\n",
    "print(paste0(\"Out-of-Sample MSE OLS: \", mse1_out))\n",
    "print(paste0(\"Out-of-Sample R-squared OLS: \", rsquared_out))\n",
    "\n",
    "mse2_out <- round(mean((first_price_hold_out - yhat.lasso.min)^2),digits=3)\n",
    "rsquared2_out <- round(1-mean((first_price_hold_out - yhat.lasso.min)^2)/mean((first_price_hold_out - mean(first_price_hold_out))^2),digits=3)\n",
    "print(paste0(\"Out-of-Sample MSE Lasso (lambda.min): \", mse2_out))\n",
    "print(paste0(\"Out-of-Sample R-squared Lasso (lambda.min): \", rsquared2_out))\n",
    "\n",
    "mse3_out <- round(mean((first_price_hold_out - yhat.lasso.1se)^2),digits=3)\n",
    "rsquared3_out <- round(1-mean((first_price_hold_out - yhat.lasso.1se)^2)/mean((first_price_hold_out - mean(first_price_hold_out))^2),digits=3)\n",
    "print(paste0(\"Out-of-Sample MSE Lassso (lambda.1se): \", mse3_out))\n",
    "print(paste0(\"Out-of-Sample R-squared Lasso (lambda.1se): \", rsquared3_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could improve the performance of the LASSO prediction by adding more covariates (e.g., interactions). We can check the performance of the Risge estimator by setting *p = 0*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Exercises:\n",
    "\n",
    "1. Estimate the Post-Lasso coefficients. Do they differ from the Lasso coeffieicents? Do the performances of the Lasso and Post-Lasso estimators differ?\n",
    "\n",
    "2. Predict the used car prices using a Rdge instead of a Lasso model. Which estimator shows the better performance?\n",
    "\n",
    "3. How do the results change when you increase the sample size to 104,721 observations?\n",
    "\n",
    "2. Replace the outcome variable 'first_price' with the 'overprice' dummy. Fit a linear and logit Lasso model. How do the models differ from each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
